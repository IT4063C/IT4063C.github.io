"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[4860],{74544:(t,e,a)=>{a.r(e),a.d(e,{assets:()=>r,contentTitle:()=>s,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var n=a(87462),d=(a(67294),a(3905));a(8209);const i={title:"Importing from Different Data Sources",sidebar_position:2,draft:!1},s=void 0,o={unversionedId:"working-with-data/data-sources",id:"working-with-data/data-sources",title:"Importing from Different Data Sources",description:"We can construct a DataFrame from a variety of data sources. The most common data sources are:",source:"@site/content/course-notes/5.working-with-data/2.data-sources.md",sourceDirName:"5.working-with-data",slug:"/working-with-data/data-sources",permalink:"/course-notes/working-with-data/data-sources",draft:!1,editUrl:"https://github.com/IT4063C/IT4063C.github.io/tree/main/content/course-notes/5.working-with-data/2.data-sources.md",tags:[],version:"current",lastUpdatedBy:"Yahya Gilany",lastUpdatedAt:1662926689,formattedLastUpdatedAt:"Sep 11, 2022",sidebarPosition:2,frontMatter:{title:"Importing from Different Data Sources",sidebar_position:2,draft:!1},sidebar:"notes",previous:{title:"Numbers in Computers",permalink:"/course-notes/working-with-data/numbers-in-computers"}},r={},l=[{value:"Importing Data from CSV",id:"importing-data-from-csv",level:2},{value:"Downloading Dataset from Kaggle using <code>OpenDatasets</code>",id:"downloading-dataset-from-kaggle-using-opendatasets",level:3},{value:"Import Data from an API",id:"import-data-from-an-api",level:2},{value:"US Census Data",id:"us-census-data",level:3},{value:"John Hopkins Covid API",id:"john-hopkins-covid-api",level:3},{value:"Importing Data using Socrata",id:"importing-data-using-socrata",level:2},{value:"Cincinnati Datasets",id:"cincinnati-datasets",level:3},{value:"Importing Data from SQL (Work-in-progress)",id:"importing-data-from-sql-work-in-progress",level:2}],f=t=>function(e){return console.warn("Component "+t+" was not imported, exported, or provided by MDXProvider as global scope"),(0,d.kt)("div",e)},h=f("HTMLOutputBlock"),p=f("CodeOutputBlock"),m={toc:l};function c(t){let{components:e,...i}=t;return(0,d.kt)("wrapper",(0,n.Z)({},m,i,{components:e,mdxType:"MDXLayout"}),(0,d.kt)("p",null,"We can construct a ",(0,d.kt)("inlineCode",{parentName:"p"},"DataFrame")," from a variety of data sources. The most common data sources are:"),(0,d.kt)("ul",null,(0,d.kt)("li",{parentName:"ul"},"CSV files"),(0,d.kt)("li",{parentName:"ul"},"Excel files"),(0,d.kt)("li",{parentName:"ul"},"SQL databases"),(0,d.kt)("li",{parentName:"ul"},"JSON files"),(0,d.kt)("li",{parentName:"ul"},"HTML files")),(0,d.kt)("p",null,"In this notes, we see some of those examples in action"),(0,d.kt)("h2",{id:"importing-data-from-csv"},"Importing Data from CSV"),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\nimport numpy as np\n")),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'url = "https://raw.github.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/tips.csv"\n\ntips = pd.read_csv(url)\ntips.head()\n')),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},'<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.99</td>\n      <td>1.01</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.34</td>\n      <td>1.66</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.01</td>\n      <td>3.50</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.68</td>\n      <td>3.31</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.59</td>\n      <td>3.61</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n'))),(0,d.kt)("p",null,"The ",(0,d.kt)("inlineCode",{parentName:"p"},".head()")," function gets you the first 5 elements of the data frame to show what the data would look like."),(0,d.kt)("p",null,"You could also use the function ",(0,d.kt)("inlineCode",{parentName:"p"},"describe()")," which return summary statistics about the dataset"),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},"tips.describe()\n")),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},'<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>244.000000</td>\n      <td>244.000000</td>\n      <td>244.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>19.785943</td>\n      <td>2.998279</td>\n      <td>2.569672</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.902412</td>\n      <td>1.383638</td>\n      <td>0.951100</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.070000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>13.347500</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>17.795000</td>\n      <td>2.900000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24.127500</td>\n      <td>3.562500</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>50.810000</td>\n      <td>10.000000</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n'))),(0,d.kt)("h3",{id:"downloading-dataset-from-kaggle-using-opendatasets"},"Downloading Dataset from Kaggle using ",(0,d.kt)("inlineCode",{parentName:"h3"},"OpenDatasets")),(0,d.kt)("p",null,"In cases where you're trying to use datasets that are available on online sources like ",(0,d.kt)("inlineCode",{parentName:"p"},"Kaggle"),". You can continue to use the URL directly, if the source makes one available. Or you could use a tool such as ",(0,d.kt)("inlineCode",{parentName:"p"},"opendatasets"),".\n",(0,d.kt)("inlineCode",{parentName:"p"},"opendatasets")," is a Python library for downloading datasets from online sources like ",(0,d.kt)("inlineCode",{parentName:"p"},"Kaggle")," and ",(0,d.kt)("inlineCode",{parentName:"p"},"Google Drive")," using a simple Python command."),(0,d.kt)("p",null,"The following examples show how you can (DOWNLOAD) the US Elections Dataset available via ",(0,d.kt)("inlineCode",{parentName:"p"},"Kaggle"),". You will be asked to provide your username and authentication API key (that's not the same as your account password)."),(0,d.kt)("p",null,(0,d.kt)("strong",{parentName:"p"},"To get your Kaggle API Key:"),"\n",(0,d.kt)("img",{alt:"Where to get your Kaggle API Key",src:a(37627).Z,width:"3584",height:"1972"})),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},"import opendatasets as od\ndataset_url = 'https://www.kaggle.com/tunguz/us-elections-dataset'\nod.download(dataset_url)\n")),(0,d.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"    Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n    Your Kaggle username:Your Kaggle Key:Downloading us-elections-dataset.zip to ./us-elections-dataset\n\n\n    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133k/133k [00:00<00:00, 1.49MB/s]\n\n    \n\n\n    \n"))),(0,d.kt)("p",null,"Once downloaded, you can Import the CSV file into a data frame."),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},"## import CSv file from local folder into a dataframe\nelections = pd.read_csv('./us-elections-dataset/1976-2020-president.csv')\nelections.head()\n")),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},'<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>year</th>\n      <th>state</th>\n      <th>state_po</th>\n      <th>state_fips</th>\n      <th>state_cen</th>\n      <th>state_ic</th>\n      <th>office</th>\n      <th>candidate</th>\n      <th>party_detailed</th>\n      <th>writein</th>\n      <th>candidatevotes</th>\n      <th>totalvotes</th>\n      <th>version</th>\n      <th>notes</th>\n      <th>party_simplified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1976</td>\n      <td>ALABAMA</td>\n      <td>AL</td>\n      <td>1</td>\n      <td>63</td>\n      <td>41</td>\n      <td>US PRESIDENT</td>\n      <td>CARTER, JIMMY</td>\n      <td>DEMOCRAT</td>\n      <td>False</td>\n      <td>659170</td>\n      <td>1182850</td>\n      <td>20210113</td>\n      <td>NaN</td>\n      <td>DEMOCRAT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1976</td>\n      <td>ALABAMA</td>\n      <td>AL</td>\n      <td>1</td>\n      <td>63</td>\n      <td>41</td>\n      <td>US PRESIDENT</td>\n      <td>FORD, GERALD</td>\n      <td>REPUBLICAN</td>\n      <td>False</td>\n      <td>504070</td>\n      <td>1182850</td>\n      <td>20210113</td>\n      <td>NaN</td>\n      <td>REPUBLICAN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1976</td>\n      <td>ALABAMA</td>\n      <td>AL</td>\n      <td>1</td>\n      <td>63</td>\n      <td>41</td>\n      <td>US PRESIDENT</td>\n      <td>MADDOX, LESTER</td>\n      <td>AMERICAN INDEPENDENT PARTY</td>\n      <td>False</td>\n      <td>9198</td>\n      <td>1182850</td>\n      <td>20210113</td>\n      <td>NaN</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1976</td>\n      <td>ALABAMA</td>\n      <td>AL</td>\n      <td>1</td>\n      <td>63</td>\n      <td>41</td>\n      <td>US PRESIDENT</td>\n      <td>BUBAR, BENJAMIN ""BEN""</td>\n      <td>PROHIBITION</td>\n      <td>False</td>\n      <td>6669</td>\n      <td>1182850</td>\n      <td>20210113</td>\n      <td>NaN</td>\n      <td>OTHER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1976</td>\n      <td>ALABAMA</td>\n      <td>AL</td>\n      <td>1</td>\n      <td>63</td>\n      <td>41</td>\n      <td>US PRESIDENT</td>\n      <td>HALL, GUS</td>\n      <td>COMMUNIST PARTY USE</td>\n      <td>False</td>\n      <td>1954</td>\n      <td>1182850</td>\n      <td>20210113</td>\n      <td>NaN</td>\n      <td>OTHER</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n'))),(0,d.kt)("h2",{id:"import-data-from-an-api"},"Import Data from an API"),(0,d.kt)("p",null,"To import data using an HTTP API in Python, you have multiple options for the HTTP client libraries. The one I choose and use here is ",(0,d.kt)("inlineCode",{parentName:"p"},"requests"),". Here I will show you how you can use ",(0,d.kt)("inlineCode",{parentName:"p"},"requests")," to query data from the US Census Data, and from the John Hopkins COVID APIs."),(0,d.kt)("p",null,"The most basic example is the following:"),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},"import requests\n\nx = requests.get('https://w3schools.com/python/demopage.htm')\n\nprint(x.text)\n")),(0,d.kt)("p",null,"However, depending on the API provider, we may need to pass additional configurations and options in the request. We'll see that in the following examples"),(0,d.kt)("h3",{id:"us-census-data"},"US Census Data"),(0,d.kt)("p",null,"The US Census Bureau provides machine-readable dataset via a developer API. "),(0,d.kt)("blockquote",null,(0,d.kt)("p",{parentName:"blockquote"},"Developers could use the statistics available through this API to create apps that:"),(0,d.kt)("ol",{parentName:"blockquote"},(0,d.kt)("li",{parentName:"ol"},"Show commuting patterns for every city in America."),(0,d.kt)("li",{parentName:"ol"},"Display the latest numbers on owners and renters in a neighborhood someone may want to live in."),(0,d.kt)("li",{parentName:"ol"},"Provide a local government a range of socioeconomic statistics on its population."))),(0,d.kt)("p",null,"Here are ",(0,d.kt)("a",{parentName:"p",href:"https://www.census.gov/data/developers/data-sets.html"},"some of the datasets available that you can use")),(0,d.kt)("p",null,"Each dataset provides technical documentation for the different variables you could get from that Particular API. Here's ",(0,d.kt)("a",{parentName:"p",href:"https://api.census.gov/data/2020/dec/pl/variables.html"},"an example")),(0,d.kt)("ul",null,(0,d.kt)("li",{parentName:"ul"},(0,d.kt)("a",{parentName:"li",href:"https://www.census.gov/content/dam/Census/library/publications/2020/acs/acs_api_handbook_2020_ch02.pdf"},"Working with US Census Data - PDF Guide"))),(0,d.kt)("p",null,"To construct a request with ",(0,d.kt)("inlineCode",{parentName:"p"},"requests")," we need to determine the URL we need to send the request to."),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nHOST = "https://api.census.gov/data"\nyear = "2022"\ndataset = "cps/basic/apr"\nbase_url = "/".join([HOST, year, dataset]) # JOIN the variables with a `/` separator https://api.census.gov/data/2022/cps/basic/apr\n\n# The dataset is huge and contains a lot of data, so we\'ll request a subset of the available variables.\ndataset_variables = ["GEDIV","HRMIS","PENATVTY"] \n\npredicates = {}\npredicates["get"] = ",".join(dataset_variables) # JOIN the variables with a `,` separator\npredicates["for"] = "state:*"\n\nresponse = requests.get(base_url, params=predicates)\n\ncensus_data = pd.DataFrame.from_records(response.json()[1:], columns=response.json()[0])\nprint(census_data.head())\n')),(0,d.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"      GEDIV HRMIS PENATVTY state\n    0     8     8      303     4\n    1     8     8      303     4\n    2     8     8       57     4\n    3     8     8       57     4\n    4     7     2       57     5\n"))),(0,d.kt)("p",null,"This ",(0,d.kt)("a",{parentName:"p",href:"https://api.census.gov/data/2022/cps/basic/apr/variables.html"},"link here")," describes what those variables mean."),(0,d.kt)("p",null,"Also, you note that even the states are presented with some numerical values. to get the values of those state IDs, I'll send another request to another dataset"),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nHOST = "https://api.census.gov/data"\nyear = "2017"\ndataset = "acs/acs5"\nbase_url = "/".join([HOST, year, dataset]) # JOIN the variables with a `/` separator https://api.census.gov/data/2022/cps/basic/apr\n\ndataset_variables = ["NAME"]\npredicates = {}\npredicates["get"] = ",".join(dataset_variables)\npredicates["for"] = "state:*"\n\nr = requests.get(base_url, params=predicates)\nstates = pd.DataFrame.from_records(r.json()[1:], columns=r.json()[0])\nprint(states.head())\n')),(0,d.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"              NAME state\n    0  Mississippi    28\n    1     Missouri    29\n    2      Montana    30\n    3     Nebraska    31\n    4       Nevada    32\n"))),(0,d.kt)("p",null,"You could subset the data recieved to find the State Numerical Code for the ",(0,d.kt)("inlineCode",{parentName:"p"},"Ohio")),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'# Find the state code with the name "Ohio"\nprint(states[states["NAME"] == "Ohio"])\n')),(0,d.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"        NAME state\n    16  Ohio    39\n"))),(0,d.kt)("p",null,"or you could just combine and merge the 2 data sets on the state ID, so we end up with a single dataset with all the information we need."),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'# Merge census_data and states\nfull_census_data = pd.merge(census_data, states, on="state")\nfull_census_data.head() # Print the first 5 rows\n')),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},'<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>GEDIV</th>\n      <th>HRMIS</th>\n      <th>PENATVTY</th>\n      <th>state</th>\n      <th>NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>6</td>\n      <td>57</td>\n      <td>40</td>\n      <td>Oklahoma</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>6</td>\n      <td>57</td>\n      <td>40</td>\n      <td>Oklahoma</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>6</td>\n      <td>57</td>\n      <td>40</td>\n      <td>Oklahoma</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>6</td>\n      <td>57</td>\n      <td>40</td>\n      <td>Oklahoma</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>3</td>\n      <td>57</td>\n      <td>40</td>\n      <td>Oklahoma</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n'))),(0,d.kt)("h3",{id:"john-hopkins-covid-api"},"John Hopkins Covid API"),(0,d.kt)("p",null,"John Hopkins University | Cornoavirus Resources Center have been collecting and publishing data regarding COVID-19 since day one.\nYou can learn more about that and ",(0,d.kt)("a",{parentName:"p",href:"https://coronavirus.jhu.edu/about/how-to-use-our-data"},"find official resources for how to use the data here")),(0,d.kt)("p",null,"I believe someone is publishing those datasets by means of API through the RapidAPI platform. Whether it's an official resource or not, the goal of this exercise is to show you how to work with APIs in general."),(0,d.kt)("p",null,"You can see a very easy to understand documentation of ",(0,d.kt)("a",{parentName:"p",href:"https://rapidapi.com/axisbits-axisbits-default/api/covid-19-statistics/"},"how to use the API here"),". "),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nurl = "https://covid-19-statistics.p.rapidapi.com/reports"\n\nquerystring = {"region_province":"Ohio","iso":"USA","region_name":"US","q":"US Ohio","date":"2020-04-16"}\n\nheaders = {\n    "X-RapidAPI-Key": "b6d38dbbd1msh33a9b59e4f6ddefp148a30jsn8bb7487ef097",\n    "X-RapidAPI-Host": "covid-19-statistics.p.rapidapi.com"\n}\n\nresponse = requests.request("GET", url, headers=headers, params=querystring)\n\nprint(response.json()["data"])\n\n# save json result into a pandas dataframe\ncovid_data = pd.DataFrame(response.json()["data"])\ncovid_data.head()\n')),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"[{'date': '2020-04-16', 'confirmed': 8414, 'deaths': 407, 'recovered': 0, 'confirmed_diff': 620, 'deaths_diff': 45, 'recovered_diff': 0, 'last_update': '2020-04-16 23:30:51', 'active': 8007, 'active_diff': 575, 'fatality_rate': 0.0484, 'region': {'iso': 'USA', 'name': 'US', 'province': 'Ohio', 'lat': '40.3888', 'long': '-82.7649', 'cities': [{'name': 'Adams', 'date': '2020-04-16', 'fips': 39001, 'lat': '38.84541072', 'long': '-83.4718964', 'confirmed': 3, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Allen', 'date': '2020-04-16', 'fips': 39003, 'lat': '40.77285242', 'long': '-84.10802343', 'confirmed': 57, 'deaths': 6, 'confirmed_diff': 6, 'deaths_diff': 2, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Ashland', 'date': '2020-04-16', 'fips': 39005, 'lat': '40.84772277', 'long': '-82.27280781', 'confirmed': 5, 'deaths': 0, 'confirmed_diff': -1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Ashtabula', 'date': '2020-04-16', 'fips': 39007, 'lat': '41.70860332', 'long': '-80.74830218', 'confirmed': 45, 'deaths': 3, 'confirmed_diff': 9, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Athens', 'date': '2020-04-16', 'fips': 39009, 'lat': '39.33425634', 'long': '-82.04278644', 'confirmed': 3, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Auglaize', 'date': '2020-04-16', 'fips': 39011, 'lat': '40.55998859', 'long': '-84.22421429999999', 'confirmed': 19, 'deaths': 1, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Belmont', 'date': '2020-04-16', 'fips': 39013, 'lat': '40.01625942', 'long': '-80.9924051', 'confirmed': 59, 'deaths': 3, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Brown', 'date': '2020-04-16', 'fips': 39015, 'lat': '38.93416837', 'long': '-83.86788395', 'confirmed': 8, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Butler', 'date': '2020-04-16', 'fips': 39017, 'lat': '39.44012838', 'long': '-84.57388716', 'confirmed': 148, 'deaths': 2, 'confirmed_diff': 15, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Carroll', 'date': '2020-04-16', 'fips': 39019, 'lat': '40.578968599999996', 'long': '-81.09178213', 'confirmed': 14, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Champaign', 'date': '2020-04-16', 'fips': 39021, 'lat': '40.13923427', 'long': '-83.76875242', 'confirmed': 6, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Clark', 'date': '2020-04-16', 'fips': 39023, 'lat': '39.91592258', 'long': '-83.78498252', 'confirmed': 23, 'deaths': 0, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Clermont', 'date': '2020-04-16', 'fips': 39025, 'lat': '39.04847534', 'long': '-84.15375786', 'confirmed': 60, 'deaths': 1, 'confirmed_diff': 11, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Clinton', 'date': '2020-04-16', 'fips': 39027, 'lat': '39.41485808', 'long': '-83.80852286', 'confirmed': 23, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Columbiana', 'date': '2020-04-16', 'fips': 39029, 'lat': '40.76932373', 'long': '-80.78094576', 'confirmed': 136, 'deaths': 10, 'confirmed_diff': 13, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Coshocton', 'date': '2020-04-16', 'fips': 39031, 'lat': '40.30096166', 'long': '-81.91729018', 'confirmed': 16, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Crawford', 'date': '2020-04-16', 'fips': 39033, 'lat': '40.85065156', 'long': '-82.91989099', 'confirmed': 26, 'deaths': 0, 'confirmed_diff': 3, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Cuyahoga', 'date': '2020-04-16', 'fips': 39035, 'lat': '41.424119', 'long': '-81.65918339', 'confirmed': 1331, 'deaths': 42, 'confirmed_diff': 50, 'deaths_diff': 3, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Darke', 'date': '2020-04-16', 'fips': 39037, 'lat': '40.13412966', 'long': '-84.6194517', 'confirmed': 55, 'deaths': 10, 'confirmed_diff': 3, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Defiance', 'date': '2020-04-16', 'fips': 39039, 'lat': '41.32398837', 'long': '-84.49076944', 'confirmed': 12, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Delaware', 'date': '2020-04-16', 'fips': 39041, 'lat': '40.27942393', 'long': '-83.00457058', 'confirmed': 114, 'deaths': 3, 'confirmed_diff': 6, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Erie', 'date': '2020-04-16', 'fips': 39043, 'lat': '41.36796058', 'long': '-82.62904521', 'confirmed': 19, 'deaths': 1, 'confirmed_diff': 3, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Fairfield', 'date': '2020-04-16', 'fips': 39045, 'lat': '39.75107189', 'long': '-82.63088163', 'confirmed': 96, 'deaths': 2, 'confirmed_diff': 4, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Fayette', 'date': '2020-04-16', 'fips': 39047, 'lat': '39.56021306', 'long': '-83.4562016', 'confirmed': 12, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Franklin', 'date': '2020-04-16', 'fips': 39049, 'lat': '39.96995815', 'long': '-83.01115755', 'confirmed': 1212, 'deaths': 19, 'confirmed_diff': 110, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Fulton', 'date': '2020-04-16', 'fips': 39051, 'lat': '41.60213491', 'long': '-84.12571393', 'confirmed': 10, 'deaths': 0, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Gallia', 'date': '2020-04-16', 'fips': 39053, 'lat': '38.82708533', 'long': '-82.31647569', 'confirmed': 6, 'deaths': 1, 'confirmed_diff': -2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Geauga', 'date': '2020-04-16', 'fips': 39055, 'lat': '41.49952319', 'long': '-81.17935342', 'confirmed': 92, 'deaths': 4, 'confirmed_diff': 10, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Greene', 'date': '2020-04-16', 'fips': 39057, 'lat': '39.69116283', 'long': '-83.89032084', 'confirmed': 33, 'deaths': 2, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Guernsey', 'date': '2020-04-16', 'fips': 39059, 'lat': '40.05026529', 'long': '-81.49248905', 'confirmed': 10, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Hamilton', 'date': '2020-04-16', 'fips': 39061, 'lat': '39.19673558', 'long': '-84.54502924', 'confirmed': 615, 'deaths': 29, 'confirmed_diff': 21, 'deaths_diff': 2, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Hancock', 'date': '2020-04-16', 'fips': 39063, 'lat': '41.00250487', 'long': '-83.66838948', 'confirmed': 25, 'deaths': 1, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Hardin', 'date': '2020-04-16', 'fips': 39065, 'lat': '40.66015414', 'long': '-83.65929931', 'confirmed': 12, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Harrison', 'date': '2020-04-16', 'fips': 39067, 'lat': '40.29380509', 'long': '-81.09068544', 'confirmed': 1, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Henry', 'date': '2020-04-16', 'fips': 39069, 'lat': '41.333964200000004', 'long': '-84.06830637', 'confirmed': 2, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Highland', 'date': '2020-04-16', 'fips': 39071, 'lat': '39.1839264', 'long': '-83.60331456', 'confirmed': 7, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Hocking', 'date': '2020-04-16', 'fips': 39073, 'lat': '39.49537927', 'long': '-82.47991446', 'confirmed': 4, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Holmes', 'date': '2020-04-16', 'fips': 39075, 'lat': '40.56163713', 'long': '-81.92635677', 'confirmed': 3, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Huron', 'date': '2020-04-16', 'fips': 39077, 'lat': '41.14651175', 'long': '-82.59867951', 'confirmed': 16, 'deaths': 1, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Jackson', 'date': '2020-04-16', 'fips': 39079, 'lat': '39.01914254', 'long': '-82.61818559999998', 'confirmed': 3, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Jefferson', 'date': '2020-04-16', 'fips': 39081, 'lat': '40.38614126', 'long': '-80.76259514', 'confirmed': 24, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Knox', 'date': '2020-04-16', 'fips': 39083, 'lat': '40.39830217', 'long': '-82.42027563', 'confirmed': 11, 'deaths': 1, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Lake', 'date': '2020-04-16', 'fips': 39085, 'lat': '41.69710807', 'long': '-81.23676539', 'confirmed': 127, 'deaths': 6, 'confirmed_diff': 3, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Lawrence', 'date': '2020-04-16', 'fips': 39087, 'lat': '38.59743452', 'long': '-82.53466552', 'confirmed': 19, 'deaths': 0, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Licking', 'date': '2020-04-16', 'fips': 39089, 'lat': '40.09136236', 'long': '-82.48185785', 'confirmed': 92, 'deaths': 4, 'confirmed_diff': 4, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Logan', 'date': '2020-04-16', 'fips': 39091, 'lat': '40.38996525', 'long': '-83.76784341', 'confirmed': 8, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Lorain', 'date': '2020-04-16', 'fips': 39093, 'lat': '41.29553751', 'long': '-82.15083537', 'confirmed': 221, 'deaths': 9, 'confirmed_diff': 18, 'deaths_diff': 2, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Lucas', 'date': '2020-04-16', 'fips': 39095, 'lat': '41.62101218', 'long': '-83.65468618', 'confirmed': 644, 'deaths': 28, 'confirmed_diff': 48, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Madison', 'date': '2020-04-16', 'fips': 39097, 'lat': '39.89381073', 'long': '-83.40178317', 'confirmed': 29, 'deaths': 3, 'confirmed_diff': 5, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Mahoning', 'date': '2020-04-16', 'fips': 39099, 'lat': '41.01631101', 'long': '-80.77287029', 'confirmed': 512, 'deaths': 42, 'confirmed_diff': 26, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Marion', 'date': '2020-04-16', 'fips': 39101, 'lat': '40.58610662', 'long': '-83.15736305', 'confirmed': 276, 'deaths': 1, 'confirmed_diff': 112, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Medina', 'date': '2020-04-16', 'fips': 39103, 'lat': '41.11770589', 'long': '-81.89986209999998', 'confirmed': 126, 'deaths': 10, 'confirmed_diff': 4, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Meigs', 'date': '2020-04-16', 'fips': 39105, 'lat': '39.09224872', 'long': '-82.0305041', 'confirmed': 2, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Mercer', 'date': '2020-04-16', 'fips': 39107, 'lat': '40.54043046', 'long': '-84.62912742', 'confirmed': 13, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Miami', 'date': '2020-04-16', 'fips': 39109, 'lat': '40.0543329', 'long': '-84.22871271', 'confirmed': 127, 'deaths': 22, 'confirmed_diff': 2, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Monroe', 'date': '2020-04-16', 'fips': 39111, 'lat': '39.72984936', 'long': '-81.08464734', 'confirmed': 2, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Montgomery', 'date': '2020-04-16', 'fips': 39113, 'lat': '39.75394919', 'long': '-84.29050975', 'confirmed': 213, 'deaths': 8, 'confirmed_diff': 2, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Morgan', 'date': '2020-04-16', 'fips': 39115, 'lat': '39.62081738', 'long': '-81.85308173', 'confirmed': 3, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Morrow', 'date': '2020-04-16', 'fips': 39117, 'lat': '40.52363560000001', 'long': '-82.7892599', 'confirmed': 14, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Muskingum', 'date': '2020-04-16', 'fips': 39119, 'lat': '39.96575964', 'long': '-81.94363275', 'confirmed': 8, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Noble', 'date': '2020-04-16', 'fips': 39121, 'lat': '39.76818851', 'long': '-81.45937183', 'confirmed': 3, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Ottawa', 'date': '2020-04-16', 'fips': 39123, 'lat': '41.53781826', 'long': '-83.0940185', 'confirmed': 17, 'deaths': 0, 'confirmed_diff': 5, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Paulding', 'date': '2020-04-16', 'fips': 39125, 'lat': '41.11676341', 'long': '-84.5801017', 'confirmed': 5, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Perry', 'date': '2020-04-16', 'fips': 39127, 'lat': '39.73508655', 'long': '-82.23804971', 'confirmed': 8, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Pickaway', 'date': '2020-04-16', 'fips': 39129, 'lat': '39.64170392', 'long': '-83.0243386', 'confirmed': 196, 'deaths': 4, 'confirmed_diff': 24, 'deaths_diff': 4, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Pike', 'date': '2020-04-16', 'fips': 39131, 'lat': '39.07634001', 'long': '-83.06769584', 'confirmed': 1, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Portage', 'date': '2020-04-16', 'fips': 39133, 'lat': '41.16793482', 'long': '-81.19735782', 'confirmed': 162, 'deaths': 24, 'confirmed_diff': 4, 'deaths_diff': 2, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Preble', 'date': '2020-04-16', 'fips': 39135, 'lat': '39.7420247', 'long': '-84.64787018', 'confirmed': 20, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Putnam', 'date': '2020-04-16', 'fips': 39137, 'lat': '41.02094889', 'long': '-84.1336111', 'confirmed': 4, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Richland', 'date': '2020-04-16', 'fips': 39139, 'lat': '40.77180308', 'long': '-82.53799609999999', 'confirmed': 48, 'deaths': 1, 'confirmed_diff': 4, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Ross', 'date': '2020-04-16', 'fips': 39141, 'lat': '39.33705391', 'long': '-83.06000914', 'confirmed': 26, 'deaths': 0, 'confirmed_diff': 5, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Sandusky', 'date': '2020-04-16', 'fips': 39143, 'lat': '41.35624126', 'long': '-83.137872', 'confirmed': 14, 'deaths': 2, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Scioto', 'date': '2020-04-16', 'fips': 39145, 'lat': '38.80270163', 'long': '-82.98907345', 'confirmed': 5, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Seneca', 'date': '2020-04-16', 'fips': 39147, 'lat': '41.12351311', 'long': '-83.12783209', 'confirmed': 11, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Shelby', 'date': '2020-04-16', 'fips': 39149, 'lat': '40.33163494', 'long': '-84.20258189', 'confirmed': 28, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Stark', 'date': '2020-04-16', 'fips': 39151, 'lat': '40.81482476', 'long': '-81.36437305', 'confirmed': 204, 'deaths': 21, 'confirmed_diff': 28, 'deaths_diff': 4, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Summit', 'date': '2020-04-16', 'fips': 39153, 'lat': '41.12464734', 'long': '-81.53123079', 'confirmed': 310, 'deaths': 16, 'confirmed_diff': 16, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Trumbull', 'date': '2020-04-16', 'fips': 39155, 'lat': '41.31735028', 'long': '-80.76109643', 'confirmed': 203, 'deaths': 14, 'confirmed_diff': 4, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Tuscarawas', 'date': '2020-04-16', 'fips': 39157, 'lat': '40.44214695', 'long': '-81.47226262', 'confirmed': 29, 'deaths': 0, 'confirmed_diff': 1, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Unassigned', 'date': '2020-04-16', 'fips': 90039, 'lat': None, 'long': None, 'confirmed': 0, 'deaths': 16, 'confirmed_diff': 0, 'deaths_diff': 16, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Union', 'date': '2020-04-16', 'fips': 39159, 'lat': '40.30016061', 'long': '-83.37239023', 'confirmed': 11, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Van Wert', 'date': '2020-04-16', 'fips': 39161, 'lat': '40.8554138', 'long': '-84.59111700000003', 'confirmed': 2, 'deaths': 0, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Warren', 'date': '2020-04-16', 'fips': 39165, 'lat': '39.42581994', 'long': '-84.16557457', 'confirmed': 89, 'deaths': 4, 'confirmed_diff': 4, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Washington', 'date': '2020-04-16', 'fips': 39167, 'lat': '39.45690571', 'long': '-81.49121382', 'confirmed': 53, 'deaths': 5, 'confirmed_diff': 6, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Wayne', 'date': '2020-04-16', 'fips': 39169, 'lat': '40.82925852', 'long': '-81.88844833', 'confirmed': 66, 'deaths': 11, 'confirmed_diff': 10, 'deaths_diff': 1, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Williams', 'date': '2020-04-16', 'fips': 39171, 'lat': '41.56052014', 'long': '-84.58429552', 'confirmed': 6, 'deaths': 1, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Wood', 'date': '2020-04-16', 'fips': 39173, 'lat': '41.36224827', 'long': '-83.62285108', 'confirmed': 67, 'deaths': 5, 'confirmed_diff': 3, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}, {'name': 'Wyandot', 'date': '2020-04-16', 'fips': 39175, 'lat': '40.84339621', 'long': '-83.30734173', 'confirmed': 14, 'deaths': 2, 'confirmed_diff': 0, 'deaths_diff': 0, 'last_update': '2020-04-16 23:30:51'}]}}]\n")),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>confirmed</th>\n      <th>deaths</th>\n      <th>recovered</th>\n      <th>confirmed_diff</th>\n      <th>deaths_diff</th>\n      <th>recovered_diff</th>\n      <th>last_update</th>\n      <th>active</th>\n      <th>active_diff</th>\n      <th>fatality_rate</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-04-16</td>\n      <td>8414</td>\n      <td>407</td>\n      <td>0</td>\n      <td>620</td>\n      <td>45</td>\n      <td>0</td>\n      <td>2020-04-16 23:30:51</td>\n      <td>8007</td>\n      <td>575</td>\n      <td>0.0484</td>\n      <td>{'iso': 'USA', 'name': 'US', 'province': 'Ohio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n"))),(0,d.kt)("h2",{id:"importing-data-using-socrata"},"Importing Data using Socrata"),(0,d.kt)("p",null,"The Socrata Open Data API allows you to programmatically access a wealth of open data resources from governments, non-profits, and NGOs around the world. "),(0,d.kt)("h3",{id:"cincinnati-datasets"},"Cincinnati Datasets"),(0,d.kt)("p",null,"For example, ",(0,d.kt)("a",{parentName:"p",href:"https://www.opendatanetwork.com/entity/1600000US3915000/Cincinnati_OH/demographics.population.count?ref=search-entity&year=2018"},"here are a bunch of datasets that you can find about the City of Cincinnati")),(0,d.kt)("p",null,"For you to be able to access any of those datasets, you need to register to get an application token."),(0,d.kt)("p",null,(0,d.kt)("img",{alt:"Cincinnati Data Portal",src:a(65222).Z,width:"3584",height:"1944"})),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'import pandas as pd\nfrom sodapy import Socrata\n\n# Example authenticated client (needed for non-public datasets):\napp_token = \'REDACTED\'\n\n# client = Socrata("data.cincinnati-oh.gov", None)\nclient = Socrata("data.cincinnati-oh.gov",app_token)\n\n\n# First 2000 results, returned as JSON from API / converted to Python list of\n# dictionaries by sodapy.\nresults = client.get("rvmt-pkmq", limit=2000)\n\n# Convert to pandas DataFrame\nresults_df = pd.DataFrame.from_records(results)\nprint(results_df.columns)\n')),(0,d.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre"},"    Index(['address_x', 'latitude_x', 'longitude_x',\n           'community_council_neighborhood', 'cpd_neighborhood',\n           'sna_neighborhood', 'crashdate', 'crashseverity', 'crashseverityid',\n           'datecrashreported', 'dayofweek', 'injuries', 'instanceid',\n           'lightconditionsprimary', 'localreportno', 'mannerofcrash',\n           'roadconditionsprimary', 'roadcontour', 'roadsurface', 'unittype',\n           'typeofperson', 'weather', 'zip', 'age', 'gender', 'roadclass',\n           'roadclassdesc'],\n          dtype='object')\n"))),(0,d.kt)("h2",{id:"importing-data-from-sql-work-in-progress"},"Importing Data from SQL (Work-in-progress)"),(0,d.kt)("p",null,(0,d.kt)("img",{parentName:"p",src:"https://www.sqlitetutorial.net/wp-content/uploads/2015/11/sqlite-sample-database-color.jpg",alt:"DB Schema"})),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'from sqlalchemy import create_engine\n\n# engine = create_engine("sqlite:///:memory:")\nengine = create_engine("sqlite:///chinook.db")\n\ndbConnection = engine.connect()\n')),(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-python"},'df = pd.read_sql("SELECT * FROM genres;", dbConnection)\ndf\n')),(0,d.kt)(h,{mdxType:"HTMLOutputBlock"},(0,d.kt)("pre",null,(0,d.kt)("code",{parentName:"pre",className:"language-html"},'<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>GenreId</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jazz</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Metal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Alternative &amp; Punk</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Rock And Roll</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Blues</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Latin</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Reggae</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Pop</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Soundtrack</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>Bossa Nova</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>Easy Listening</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>Heavy Metal</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>R&amp;B/Soul</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>Electronica/Dance</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>World</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>Hip Hop/Rap</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>Science Fiction</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>TV Shows</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>Sci Fi &amp; Fantasy</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>Comedy</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>Alternative</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>Classical</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>Opera</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n'))))}c.isMDXComponent=!0},65222:(t,e,a)=>{a.d(e,{Z:()=>n});const n=a.p+"assets/images/cin-9407e04adcc73367e750e2c98c63eaaa.jpg"},37627:(t,e,a)=>{a.d(e,{Z:()=>n});const n=a.p+"assets/images/kaggle-profile-f014c6677ed1da1ed6d8adaa4bac162a.jpg"}}]);